{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "marked-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "import time\n",
    "import pathlib\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "objective-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "terminal-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transform_data={\n",
    "    \"trainData\":transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # horizontal flip and 0.5 is the position\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomRotation(45, resample=False, expand=False,\n",
    "                                              center=None),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    #transforms.Normalize([0.5],[0.5]) # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "\n",
    "]),\n",
    "    \"testData\": transforms.Compose([ transforms.Grayscale(num_output_channels=1),      \n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # horizontal flip and 0.5 is the position\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.5],[0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_transform={\n",
    "    \"trainData\":transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # horizontal flip and 0.5 is the position\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomRotation(45, resample=False, expand=False,\n",
    "                                              center=None),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    #transforms.Normalize([0.5],[0.5]) # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                            ])        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "neither-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "batchSize = 32 \n",
    "#Path for training and testing directory\n",
    "train_path='C:/automated_classification/holographic_plankton_classification-main/samples/new_training'\n",
    "\n",
    "# Split test and train dataset \n",
    "#data_transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "#                                     transforms.ToTensor()])\n",
    "dataset = ImageFolder(train_path, transform=data_transform[\"trainData\"])\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batchSize, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batchSize, shuffle=True)\n",
    "\n",
    "#train_path='C:/automated_classification/holographic_plankton_classification-main/samples/training_new/train_data'\n",
    "#test_path='C:/automated_classification/holographic_plankton_classification-main/samples/training_new/test_data'\n",
    "\n",
    "#train_loader=DataLoader(\n",
    " #   torchvision.datasets.ImageFolder(train_path,transform=transform_data[\"trainData\"]),\n",
    " #   batch_size=batchSize, shuffle=True\n",
    "#)\n",
    "#test_loader=DataLoader(\n",
    " #   torchvision.datasets.ImageFolder(test_path,transform=transform_data[\"testData\"]),\n",
    "  #  batch_size=batchSize, shuffle=True\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "polyphonic-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Decoy', 'Kbrevis', 'NullClass-autoholo']\n",
      "3\n",
      "540\n"
     ]
    }
   ],
   "source": [
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)\n",
    "numClasses=len(classes)\n",
    "print(numClasses)\n",
    "print(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "least-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureExtract=False\n",
    "usePretrained=False\n",
    "modelName = \"resnet50\"\n",
    "dropNum = 0.5\n",
    "#momentum = 0.9\n",
    "dropout = True\n",
    "mono = True\n",
    "filePath = \"C:/automated_classification/holographic_plankton_classification-main/\"\n",
    "savePath = 'C:/automated_classification/holographic_plankton_classification-main/modelGen/' + modelName + '_'\n",
    "\n",
    "def setParameterRequiresGrad(model, featureExtract):\n",
    "    if featureExtract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "def initialModel(modelName, numClasses, featureExtract, usePretrained):\n",
    "    if modelName == \"vgg19\":\n",
    "        modelUse = models.vgg19(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.features._modules['0'] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        modelUse.classifier._modules['6'] = nn.Linear(in_features=4096, out_features=numClasses, bias=True)\n",
    "\n",
    "    elif modelName == \"shufflenet_v2_x2_0\":\n",
    "        modelUse = models.shufflenet_v2_x2_0(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.conv1._modules['0'] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        if dropout:\n",
    "            modelUse.fc = nn.Sequential(nn.Dropout(dropNum),\n",
    "                                        nn.Linear(2048, numClasses, bias=True))\n",
    "        else:\n",
    "            modelUse.fc = nn.Linear(2048, numClasses, bias=True)\n",
    "\n",
    "    elif modelName == \"shufflenet_v2_x0_5\":\n",
    "        modelUse = models.shufflenet_v2_x0_5(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.conv1._modules['0'] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        if dropout:\n",
    "            modelUse.fc = nn.Sequential(nn.Dropout(dropNum),\n",
    "                                        nn.Linear(1024, numClasses, bias=True),\n",
    "                                        )\n",
    "        else:\n",
    "            modelUse.fc = nn.Linear(1024, numClasses, bias=True)\n",
    "\n",
    "\n",
    "    elif modelName == \"shufflenet_v2_x1_5\":\n",
    "        modelUse = models.shufflenet_v2_x1_5(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.conv1._modules['0'] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        if dropout:\n",
    "            modelUse.fc = nn.Sequential(nn.Dropout(dropNum),\n",
    "                                        nn.Linear(1024, numClasses, bias=True),)\n",
    "        else:\n",
    "            modelUse.fc = nn.Linear(1024, numClasses, bias=True)\n",
    "\n",
    "\n",
    "    elif modelName == \"shufflenet_v2_x1_0\":\n",
    "        modelUse = models.shufflenet_v2_x1_0(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.conv1._modules['0'] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "        if dropout:\n",
    "            modelUse.fc = nn.Sequential(nn.Dropout(dropNum),\n",
    "                                        nn.Linear(1024, numClasses, bias=True))\n",
    "        else:\n",
    "            modelUse.fc = nn.Linear(1024, numClasses, bias=True)\n",
    "\n",
    "\n",
    "    elif modelName == \"squeezenet1_1\":\n",
    "        modelUse = models.squeezenet1_1(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.features._modules['0'] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2))\n",
    "\n",
    "        modelUse.classifier = nn.Sequential(nn.Dropout(p=dropNum, inplace=False),\n",
    "                                nn.Conv2d(512, numClasses, kernel_size=(1, 1), stride=(1, 1)),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
    "\n",
    "\n",
    "\n",
    "    elif modelName == \"densenet121\":\n",
    "        modelUse = models.densenet121(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.features._modules['conv0'] = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        if dropout:\n",
    "            modelUse.classifier = nn.Sequential(nn.Dropout(dropNum),\n",
    "                                        nn.Linear(1024, numClasses, bias=True))\n",
    "        else:\n",
    "            modelUse.classifier = nn.Linear(1024, numClasses, bias=True)\n",
    "\n",
    "\n",
    "    elif modelName == \"vgg16\":\n",
    "        modelUse = models.vgg16(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.features._modules['0'] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        modelUse.classifier._modules['6'] = nn.Linear(in_features=4096, out_features=numClasses, bias=True)\n",
    "\n",
    "    elif modelName == 'mobilenet_v2':\n",
    "        modelUse = models.mobilenet_v2(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.features._modules['0']._modules['0'] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2),\n",
    "                                                                      padding=(1, 1), bias=False)\n",
    "\n",
    "        modelUse.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropNum, inplace=False),\n",
    "            nn.Linear(in_features=1280, out_features=numClasses, bias=True)\n",
    "        )\n",
    "\n",
    "    elif modelName == \"resnet18\":\n",
    "        modelUse = models.resnet18(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        numFeatures = modelUse.fc.in_features\n",
    "        if mono:\n",
    "            modelUse.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        if dropout:\n",
    "            modelUse.fc = nn.Sequential(nn.Dropout(dropNum),\n",
    "                                        nn.Linear(numFeatures, numClasses))\n",
    "        else:\n",
    "            modelUse.fc = nn.Linear(numFeatures, numClasses)\n",
    "\n",
    "    elif modelName == \"resnet34\":\n",
    "        modelUse = models.resnet34(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        numFeatures = modelUse.fc.in_features\n",
    "        if mono:\n",
    "            modelUse.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        if dropout:\n",
    "            modelUse.fc = nn.Sequential(nn.Dropout(dropNum),\n",
    "                                        nn.Linear(numFeatures, numClasses))\n",
    "        else:\n",
    "            modelUse.fc = nn.Linear(numFeatures, numClasses)\n",
    "\n",
    "    elif modelName == \"resnet50\":\n",
    "        modelUse = models.resnet50(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        numFeatures = modelUse.fc.in_features\n",
    "        if mono:\n",
    "            modelUse.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        if dropout:\n",
    "            modelUse.fc = nn.Sequential(nn.Dropout(dropNum),\n",
    "                                        nn.Linear(numFeatures, numClasses))\n",
    "        else:\n",
    "            modelUse.fc = nn.Linear(numFeatures, numClasses)\n",
    "            \n",
    "    elif modelName == \"alexnet\":\n",
    "        modelUse = models.alexnet(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.features._modules['0'] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        modelUse.classifier._modules['6'] = nn.Linear(in_features=4096, out_features=numClasses, bias=True) \n",
    "        \n",
    "    elif modelName == \"googlenet\":\n",
    "        modelUse = models.googlenet(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.conv1._modules['conv']=nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        modelUse.fc = nn.Linear(in_features=1024, out_features=numClasses, bias=True)    \n",
    "\n",
    "    else:\n",
    "        print(\"model not implemented\")\n",
    "        return None, None\n",
    "\n",
    "    return modelUse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "crucial-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePreAndRealFlag = True\n",
    "num_epochs=5\n",
    "learningRate=0.01\n",
    "\n",
    "def trainModel(model, trainLoader, testLoader, loss_function, optimizer, num_epochs):\n",
    "    bestAccuracy = 0\n",
    "    bestModuleWeight = copy.deepcopy(model.state_dict())\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    test_accuracy = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "        model.train()\n",
    "        run_accuracy=0.0\n",
    "        run_loss=0.0\n",
    "    \n",
    "        for images,labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            \n",
    "            outputs=model(images)\n",
    "            loss=loss_function(outputs,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "            run_loss+= loss.item() * images.size(0)\n",
    "            _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "            run_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "        epoch_accuracy=run_accuracy/len(train_loader.dataset)\n",
    "        epoch_loss=run_loss/len(train_loader.dataset)\n",
    "        print(\"Epoch: {} Phase: {} loss: {}, acc: {}\".format(epoch, 'train', epoch_loss, epoch_accuracy))\n",
    "\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_accuracy)\n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "        run_accuracy=0.0\n",
    "        run_loss=0.0\n",
    "        model.eval()\n",
    "        if savePreAndRealFlag:\n",
    "            preResult = []\n",
    "            realResult = []\n",
    "            \n",
    "        for images,labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs=model(images)\n",
    "            run_loss+= loss.item() * images.size(0)\n",
    "            _,prediction=torch.max(outputs.data,1)\n",
    "            run_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "            \n",
    "            if epoch>num_epochs-5:\n",
    "                if savePreAndRealFlag:\n",
    "                    preResult.append(str(prediction.view(-1).cpu().numpy()))\n",
    "                    realResult.append(str(labels.view(-1).cpu().numpy()))\n",
    "    \n",
    "        epoch_accuracy=run_accuracy/len(test_loader.dataset)\n",
    "        epoch_loss=run_loss/len(test_loader.dataset)\n",
    "        print(\"Epoch: {} Phase: {} loss: {}, acc: {}\".format(epoch, 'test', epoch_loss, epoch_accuracy))\n",
    "        \n",
    "        if epoch_accuracy > bestAccuracy:\n",
    "            bestAccuracy = epoch_accuracy\n",
    "            bestModuleWeight = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "        test_loss.append(epoch_loss)\n",
    "        test_accuracy.append(epoch_accuracy)\n",
    "    \n",
    "    if epoch >num_epochs-5:\n",
    "        if savePreAndRealFlag:\n",
    "            preFile = open(filePath +'fileOutput/' + modelName + time.strftime('%m%d%H%M')+ '_wb12_pre.txt', 'w')\n",
    "            preFile.write(str(preResult))\n",
    "            realFile = open(filePath+'fileOutput/' + modelName + time.strftime('%m%d%H%M')+ '_wb12_real.txt', 'w')\n",
    "            realFile.write(str(realResult))\n",
    "            preFile.close()\n",
    "            realFile.close()\n",
    "    model.load_state_dict(bestModuleWeight)\n",
    "    \n",
    "    return model, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "   \n",
    "    \n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "primary-sugar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Phase: train loss: 1.6120542329770546, acc: 0.5847222222222223\n",
      "Epoch: 0 Phase: test loss: 0.4913080632686615, acc: 0.3888888888888889\n",
      "Epoch: 1 Phase: train loss: 0.291911737786399, acc: 0.8796296296296297\n",
      "Epoch: 1 Phase: test loss: 0.10703909397125244, acc: 0.9444444444444444\n",
      "Epoch: 2 Phase: train loss: 0.27136013176706103, acc: 0.9069444444444444\n",
      "Epoch: 2 Phase: test loss: 0.07095745950937271, acc: 0.9537037037037037\n",
      "Epoch: 3 Phase: train loss: 0.18532473375951802, acc: 0.9337962962962963\n",
      "Epoch: 3 Phase: test loss: 0.028987597674131393, acc: 0.9296296296296296\n",
      "Epoch: 4 Phase: train loss: 0.1544133236562764, acc: 0.9416666666666667\n",
      "Epoch: 4 Phase: test loss: 0.10801286995410919, acc: 0.9648148148148148\n"
     ]
    }
   ],
   "source": [
    "modelUse = initialModel(modelName, numClasses, featureExtract=False, usePretrained=False)\n",
    "modelUse = modelUse.to(device)\n",
    "optimizer = torch.optim.Adam(modelUse.parameters(), lr=learningRate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "modelReturn, trHis, trAcc, teHis, teAcc = trainModel(modelUse, train_loader, test_loader, loss_function, optimizer, \n",
    "                                                     num_epochs)\n",
    "torch.save(modelReturn, savePath + time.strftime('%m%d%H%M') + 'wb12_res01_batch.pt')\n",
    "torch.save(modelReturn.state_dict, savePath + time.strftime('%m%d%H%M') + '_Para_res01_batch.pt')\n",
    "\n",
    "\n",
    "trainaccFile = open(savePath+ time.strftime('%m%d%H%M')+ '_trainacc.txt', 'w')\n",
    "trainaccFile.write(str(trAcc).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")) \n",
    "trainaccFile.close()\n",
    "trainlossFile = open(savePath+ time.strftime('%m%d%H%M')+ '_trainloss.txt', 'w')\n",
    "trainlossFile.write(str(trHis).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")) \n",
    "trainlossFile.close()\n",
    "testlossFile = open(savePath+ time.strftime('%m%d%H%M')+ '_testloss.txt', 'w')\n",
    "testlossFile.write(str(teHis).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")) \n",
    "testlossFile.close()\n",
    "testaccFile = open(savePath+ time.strftime('%m%d%H%M')+ '_testacc.txt', 'w')\n",
    "testaccFile.write(str(teAcc).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")) \n",
    "testaccFile.close()\n",
    "\n",
    "saveparamsFile = open(savePath+ time.strftime('%m%d%H%M%S')+ '_playingwithparams.txt', 'w')\n",
    "saveparamsFile.write(str(modelName) +\" LearningRate = \" + str(learningRate) +\" featureExtract = \" + str(featureExtract) +\" Epochnumber = \" + str(num_epochs) +\" batchsize = \" + str(batchSize) )\n",
    "saveparamsFile.close()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "residential-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images,labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "removable-newcastle",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-05c3fb74e4a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "images,labels = test_loader.dataset\n",
    "print(images.shape)\n",
    "plt.imshow( images.permute(1, 2, 0)  )\n",
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "smaller-gender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modelUse = models.vgg16(pretrained=False)\n",
    "\n",
    "print(modelUse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "starting-needle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  elif modelName == \"googlenet\":\n",
    "        modelUse = models.googlenet(pretrained=usePretrained)\n",
    "        setParameterRequiresGrad(modelUse, featureExtract)\n",
    "        if mono:\n",
    "            modelUse.conv1._modules['conv']=nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        modelUse.fc = nn.Linear(in_features=1024, out_features=numClasses, bias=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "limiting-density",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " modelUse.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    " modelUse.fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
